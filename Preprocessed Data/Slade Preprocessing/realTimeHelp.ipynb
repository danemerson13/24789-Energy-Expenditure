{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"realTimeHelp.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMepTDGBYkuzI1LL5BE5b78"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"bKjkltxbGtJA","executionInfo":{"status":"ok","timestamp":1647896150018,"user_tz":240,"elapsed":3107,"user":{"displayName":"Mikayla Schneider","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06516117965069787295"}}},"outputs":[],"source":["import sys\n","from glob import glob\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from scipy.signal import filtfilt, butter\n","from scipy import signal\n","from numpy import genfromtxt\n","from natsort import natsorted\n","import os\n","from shutil import copy\n","import csv\n","import datetime\n","import pytz\n","cwd = os.getcwd()\n","\n","def loadTrueMetInterp(met_ss_interp):\n","    num_subjs = met_ss_interp.shape[0]\n","    tv_mat = np.zeros((num_subjs, 4,30))\n","    del_list = []\n","    # make a list of each condition with non-zero vals and append them all then take the mean of that\n","    \n","    for i in range(num_subjs):\n","        met_ss_interp_avg = met_ss_interp[i,:]#np.mean(met_ss_interp,axis=0) # should be just size 5 for standing, walk, run\n","        if met_ss_interp[i,-1] != 0.0:\n","            del_list.append(i)\n","        met_ss_speeds = np.array([0.,1.,1.5,2.5,3.])\n","        tv1_sp = np.array([0.0, 0.0, 1.0, 1.0, 0.0])\n","        tv1_t = np.array([0., 4., 6., 16., 18.])\n","        tv1_int = np.arange(0,24)\n","        tv1_true_sp = np.interp(tv1_int,tv1_t,tv1_sp)\n","        tv1_true_met = np.interp(tv1_true_sp, met_ss_speeds, met_ss_interp_avg)\n","\n","        tv4_sp = np.array([1.0, 1.0, 3.0, 3.0, 1.0])\n","        tv4_t = np.array([0., 6., 10., 22., 26.])\n","        tv_int = np.arange(0,30)\n","        tv4_true_sp = np.interp(tv_int,tv4_t,tv4_sp)\n","        tv4_true_met = np.interp(tv4_true_sp, met_ss_speeds, met_ss_interp_avg)  \n","\n","        p = 30.0\n","        t = np.linspace(0,29,30)\n","        min_speed = 1.0\n","        max_speed = 1.5\n","        avg = (min_speed + max_speed)/2.0\n","        ampl = (max_speed - min_speed)/2.0\n","        tv_sine = avg + ampl*np.sin(2*3.14159*(t-p/4-6)/p)\n","        tv2_true_met = np.interp(tv_sine, met_ss_speeds, met_ss_interp_avg)\n","\n","        min_speed = 1.0\n","        max_speed = 3.00\n","        avg = (min_speed + max_speed)/2.0\n","        ampl = (max_speed - min_speed)/2.0\n","        tv_sine = avg + ampl*np.sin(2*3.14159*(t-p/4-6)/p)\n","        tv3_true_met = np.interp(tv_sine, met_ss_speeds, met_ss_interp_avg)\n","\n","        tv_mat[i,0,:24] = tv1_true_met\n","        tv_mat[i,1,:] = tv2_true_met\n","        tv_mat[i,3,:] = tv3_true_met\n","        tv_mat[i,2,:] = tv4_true_met\n","    \n","    tv_avg_mat = np.zeros((4,30))\n","    true_inds = np.zeros((4, num_subjs))\n","    for j in range(4):\n","        if j >= 2:\n","            tv_avg_mat[j,:] = np.mean(tv_mat[del_list,j,:],axis=0)\n","            true_inds[j,del_list] = 1\n","\n","        else:\n","            tv_avg_mat[j,:] = np.mean(tv_mat[:,j,:], axis=0)\n","            true_inds[j,:] = 1\n","            \n","    return tv_mat, tv_avg_mat, true_inds\n","\n","def loadRawMet(data_dir, subj, timezone):\n","    gen_files = os.listdir(data_dir+subj)\n","    for filename in gen_files:\n","        if len(filename) >= 4:\n","            if filename[-4:] == 'xlsx': # metabolics file\n","                met_array = pd.read_excel(data_dir+subj+'/'+filename, names=[\"time\",\"V02\",\"VC02\",\"HR\"], skiprows=3, usecols=[9, 14, 15, 23]) # left then right insole forces   \n","                met_array['MET'] = (met_array[\"V02\"]*16.48 + met_array[\"VC02\"]*4.48)/60.\n","                dt = [i.hour*3600 + i.minute*60 + i.second for i in met_array[\"time\"]]\n","\n","                # load starting time\n","                met_raw = np.array(pd.read_excel(data_dir+subj+'/'+filename, usecols=[4], header=None))\n","                starting_time = met_raw[0:2]\n","                test = str(starting_time[0][0]) + ' ' + str(starting_time[1][0])\n","                test_dt = datetime.datetime.strptime(test, '%m/%d/%Y %I:%M:%S %p')  \n","                test_dt = timezone.localize(test_dt)\n","                time_stamps = [test_dt + datetime.timedelta(seconds=i) for i in dt]\n","                met_array[\"time_stamp\"] = time_stamps\n","                met_array[\"dt\"] = np.array(dt) - dt[0] \n","                \n","    return met_array, time_stamps\n","\n","# gets all data between start and stop time \n","def getCondData(input_data, time_stamps, start_time, cond_len, time_stamp_label='time_stamp', tz = \"America/Los_Angeles\"):\n","    stop_time = start_time + datetime.timedelta(seconds=cond_len)\n","    mask = (input_data[time_stamp_label] > start_time) & (input_data[time_stamp_label] < stop_time)\n","    try:\n","        last_true_ind = mask.index[mask][-1]\n","        mask[last_true_ind+1] = True\n","    except:\n","        print(\"Error adding last index beyond the end of the file\")\n","    input_subset = input_data.loc[mask]\n","    first_true_ind = mask.index[mask][0]\n","    input_subset[\"dt\"] = np.array(input_subset[\"dt\"]) - np.array(input_subset[\"dt\"])[0] + (time_stamps[first_true_ind] - start_time).total_seconds()\n","    return input_subset\n","\n","\n","def watchValidationPlot(ee_interp, hr_interp, ee_met, hr, dd):\n","    fig, ax1 = plt.subplots()\n","    ax1.set_xlabel('Time (s)')\n","    ax1.set_ylabel('Energy expenditure (W)')\n","    ax1.plot(np.arange(len(ee_met)), ee_met, color='k', alpha=0.7, label='Respirometry per breath')\n","    ax1.plot(np.arange(len(dd)), dd, color='b', label='Data driven')\n","    ax1.legend(loc='lower right')\n","    fig.tight_layout()\n","    plt.show()\n","\n","# takes in input data in [time steps x feats] and computes heel strikes over sliding window\n","# returns processed matrix of processed gait cycles, stacked [gaits x binned feats]\n","def simRealStrikes(input_data, weight, height, shift_ind, stride_detect_window, detect_window, peak_height_thresh, peak_min_dist, shank_gyro_z_ind, b, a, deg2rad, old_data = False, data_rate = 100.0, addTime = False):\n","    gait_data = []\n","    t_steps, feats = input_data.shape\n","    watching_heelstrike = True\n","    watch_strike_cnt = 0 \n","    time_list = []\n","    time_of_gait = []\n","    for k in range(t_steps - stride_detect_window):\n","        stride_window = input_data[k:k+stride_detect_window]\n","        if watching_heelstrike: # if looking for heelstrike\n","            peak_list = checkPeaks(stride_window[:,shank_gyro_z_ind], b, a, peak_height_thresh, peak_min_dist, deg2rad, old_data) # check for peaks\n","            if len(peak_list) > 1: # checking if a new heel strike has occured\n","                if (stride_detect_window - peak_list[-1]) < detect_window: # peak has occured in last detect_window of data\n","                    watching_heelstrike = False # now wait a bit to detect heelstrikes again\n","                    new_gait_cycle = processRawGait(stride_window, peak_list[-2], peak_list[-1], shift_ind, b, a, weight, height, deg2rad, old_data, data_rate, addTime) # process most recent gait data\n","                    new_gait_cycle = np.expand_dims(new_gait_cycle, axis=0)\n","                    time_list.append(peak_list[-1] - peak_list[-2])\n","                    time_of_gait.append((k + peak_list[-1])/data_rate)\n","                    if len(gait_data) == 0:\n","                        gait_data = new_gait_cycle\n","                    else:\n","                        gait_data = np.concatenate((gait_data, new_gait_cycle), axis=0)\n","        else: # count until the peak has cleared the recent window\n","            if watch_strike_cnt > detect_window:\n","                watching_heelstrike = True\n","                watch_strike_cnt = 0\n","            else:\n","                watch_strike_cnt += 1        \n","    return gait_data, time_list, time_of_gait\n","\n","# for saved IMU data, make it into the same format as the real-time estimates\n","def computeEstimatesFromIMU(real_time_est, subj, cond, timezone, estimate_file_name, mass, height, shift_ind, stride_detect_window, detect_window, peak_height_thresh, peak_min_dist, shank_gyro_z_ind, b, a, deg2rad, model_weights, basal_rate, file_len_in_s = 5.0, save_gait_data=False, met_val = 0.0, overwrite = False):\n","    subj_cond_dir = real_time_est + subj + '\\\\' + cond + '\\\\'\n","    basal_rate = round(float(basal_rate), 3)\n","    data_files = os.listdir(subj_cond_dir)\n","    data_files = natsorted(data_files)\n","    sample_data = np.array([])\n","    with open(subj_cond_dir+data_files[-1], 'r') as f:\n","        reader = csv.reader(f, delimiter=',')\n","        for row in reader:\n","            init_ts = datetime.datetime.strptime(row[0],\"%d/%m/%Y %H:%M:%S\")\n","            break\n","    f.close()\n","    init_ts = timezone.localize(init_ts)\n","    for l, file in enumerate(data_files[:-1]):\n","        if (file == estimate_file_name) or (file[0:2] == 'TV'): # skip this file\n","            continue\n","        else:\n","            try:\n","                file_data = np.load(subj_cond_dir+file)\n","                if len(sample_data) == 0:\n","                    sample_data = file_data\n","                else:\n","                    sample_data = np.concatenate((sample_data, file_data), axis=0)\n","            except:\n","                pass\n","    gait_cycles,_,time_of_gait = simRealStrikes(sample_data[:,:-1], mass, height, shift_ind, stride_detect_window, detect_window, peak_height_thresh, peak_min_dist, shank_gyro_z_ind, b, a, deg2rad) \n","    num_gaits,_ = gait_cycles.shape\n","    gait_cycles = np.concatenate((np.ones((num_gaits,1)), gait_cycles), 1)\n","    if save_gait_data:\n","        save_dir = 'C:\\\\Users\\\\patty\\\\Desktop\\\\EEE\\\\RealTimeTesting\\\\results\\\\data\\\\' + subj + '\\\\' + cond + '\\\\'\n","        try:\n","            os.makedirs(save_dir)\n","        except:\n","            pass\n","        np.savetxt(save_dir+'x.csv', gait_cycles, delimiter=',')\n","        np.savetxt(save_dir+'y.csv', np.ones((num_gaits,1))*met_val, delimiter=',')\n","        \n","    estimates = np.round(np.dot(gait_cycles,model_weights),3)\n","    dt_stamps = [init_ts + datetime.timedelta(seconds=(i-file_len_in_s)) for i in time_of_gait]\n","    basal_t_thresh = 8.0\n","    offset_t = 1.0\n","    if overwrite:\n","        with open(subj_cond_dir+estimate_file_name,'w') as f:\n","            for p in range(num_gaits):\n","                if (p > 0) and ((dt_stamps[p]-dt_stamps[p-1]).total_seconds() >= basal_t_thresh): # large enough gap detected\n","                    # adding first basal point after last gait\n","                    f.write(\"{},{},{},{}\".format(time_of_gait[p-1]+offset_t, dt_stamps[p-1] + datetime.timedelta(seconds=offset_t), basal_rate, basal_rate))\n","                    f.write(\"\\n\")                \n","                    f.write(\"{},{},{},{}\".format(time_of_gait[p]-offset_t, dt_stamps[p]- datetime.timedelta(seconds=offset_t), basal_rate, basal_rate))\n","                    f.write(\"\\n\")\n","                if estimates[p] < basal_rate:\n","                    f.write(\"{},{},{},{}\".format(time_of_gait[p], dt_stamps[p], basal_rate, basal_rate))\n","                else:\n","                    f.write(\"{},{},{},{}\".format(time_of_gait[p], dt_stamps[p], estimates[p], estimates[p]))\n","                f.write(\"\\n\")\n","        f.close()   \n","\n","# compute data-driven estimates interpolated at 1-second intervals\n","def computeDDinter(real_time_est, est_col_ind, subj, cond, subj_cond_dir, estimate_file_name, timezone, loc_cond_timestamp, cond_time_s, basal_flag=False, basal_rate = 0.0):\n","    basal_t_thresh = 8.0 # number of second gap between gait cycles to estimate adjusted standing rate\n","    subjcond_time = []\n","    subjcond_dt = []\n","    subjcond_est = []\n","    with open(subj_cond_dir+estimate_file_name, 'r') as f:\n","        reader = csv.reader(f, delimiter=',')\n","        try:\n","            for row in reader:\n","                if len(row[1]) == 25:\n","                    new_dt = timezone.localize(datetime.datetime.strptime(row[1][:-6],\"%Y-%m-%d %H:%M:%S\"))\n","                elif len(row[1]) == 26:\n","                    new_dt = timezone.localize(datetime.datetime.strptime(row[1][:-7],\"%Y-%m-%d %H:%M:%S\"))\n","                else:\n","                    new_dt = timezone.localize(datetime.datetime.strptime(row[1][:-13],\"%Y-%m-%d %H:%M:%S\"))\n"," \n","                subjcond_time.append(float(row[0]))\n","                subjcond_dt.append(new_dt)\n","                subjcond_est.append(float(row[est_col_ind]))\n","        except:\n","            pass\n","    f.close()\n","    # compute time difference between start datetime and first gait cycle\n","    time_diff = (loc_cond_timestamp - subjcond_dt[0]).total_seconds()\n","    # from time vector subjtract initial gait value and time difference\n","    subjcond_time = np.array(subjcond_time)\n","    subjcond_est = np.array(subjcond_est)\n","    subjcond_time = subjcond_time - (time_diff + subjcond_time[0])\n","    # find indeces of gaits occuring after the start of the condition (time == 0) and less than end of condition (time == 300)\n","    prev_gaits = subjcond_time >= 0.0\n","    subjcond_time = subjcond_time[prev_gaits]\n","    subjcond_est = subjcond_est[prev_gaits]\n","    prev_gaits2 = subjcond_time < cond_time_s\n","    subjcond_time = subjcond_time[prev_gaits2]\n","    subjcond_est = subjcond_est[prev_gaits2]\n","    tmin = 0\n","    tmax = cond_time_s\n","    t = np.arange(tmin,tmax)\n","    dd_int = np.interp(t, subjcond_time, subjcond_est)\n","    return dd_int, subjcond_est, subjcond_time\n","    \n","# take in shank IMU vector, filter, look for thresholding & min_distance, return strike indeces\n","def checkPeaks(strike_vec, b, a, peak_height_thresh, peak_min_dist, deg2rad, old_data = False):\n","    if old_data:\n","        strike_vec_filt = signal.filtfilt(b,a,strike_vec*(-1.0/deg2rad))\n","    else:\n","        strike_vec_filt = signal.filtfilt(b,a,strike_vec)\n","    peak_list = signal.find_peaks(strike_vec_filt, height=peak_height_thresh, distance=peak_min_dist)\n","    return peak_list[0]\n","    \n","# takes data and moves the first half of the data to the second half\n","# assumes data_array is size [time steps x feature]\n","def convertBetweenLegs(data_array):\n","    array_copy = np.copy(data_array)\n","    convert_array = np.zeros(data_array.shape)\n","    gait_time_steps,_ = data_array.shape\n","    half_gait = int(gait_time_steps/2)\n","    convert_array[:half_gait,:] = array_copy[half_gait:,:]\n","    convert_array[half_gait:,:] = array_copy[:half_gait,:]\n","    return convert_array\n","    \n","# downsample the data into a discrete number of bins\n","def binData(data_array, num_bins=30):\n","    return signal.resample(data_array, num_bins) # resamples along axis = 0 by default\n","\n","# shift the data in the binned matrix to the left by the given shift_ind\n","def shiftBinData(data_array, shift_ind, num_bins=30):\n","    array_copy = np.copy(data_array)\n","    convert_array = np.zeros(data_array.shape)\n","    convert_array[:-shift_ind, :] = array_copy[shift_ind:,:]\n","    convert_array[-shift_ind:, :] = array_copy[:shift_ind,:]\n","    return convert_array\n","\n","# pass in array of data to process [time_samples x num_features] into [num_bins x num_features]\n","# start_ind, end_ind are indeces of start/end of gait cycle\n","# shift_ind is correction term for timing diff between heel strike and IMU thresh\n","# b, a are filter parameters\n","def processRawGait(data_array, start_ind, end_ind, shift_ind, b, a, weight, height, deg2rad, old_data = False, num_bins=30, addTime = False):\n","    gait_data = data_array[start_ind:end_ind, :] # crop to the gait cycle\n","    if not old_data:\n","        gait_data = gait_data*np.array([deg2rad,-deg2rad,-deg2rad,deg2rad,-deg2rad,-deg2rad,1,-1,-1,1,-1,-1]) # flip y & z, convert to rad/s\n","    filt_gait_data = signal.filtfilt(b,a,gait_data, axis=0) # low-pass filter\n","    bin_gait = binData(filt_gait_data) # discretize data into bins\n","    shift_flip_bin_gait = bin_gait.transpose() # get in shape of [feats x bins] for correct flattening\n","    model_input = shift_flip_bin_gait.flatten()\n","    if addTime:\n","        model_input = np.insert(model_input, 0, [weight, height, (end_ind-start_ind)*0.01]) # adding a 1 for the bias term at start\n","    else:\n","        model_input = np.insert(model_input, 0, [weight, height]) # adding a 1 for the bias term at start\n","    return model_input\n","\n","\n","def mapd(vec1, vec2): # mean absolute percent difference\n","    return np.abs(vec1 - vec2) / ((vec1 + vec2)/2)\n","\n","def compute_2min_met_errors(metabolics_real, met_2min_est):\n","    mae_mat = (np.abs(metabolics_real-met_2min_est)/metabolics_real)\n","    met_mape = np.mean(mae_mat)\n","    \n","    subjs_acc = np.zeros(metabolics_real.shape[0])\n","    for i in range(metabolics_real.shape[0]): # loop thru subjects\n","        correct, correct, pairwise_len = pairwise_similarity(metabolics_real[i,:], met_2min_est[i,:])\n","        subjs_acc[i] = correct/pairwise_len        \n","        \n","    ordering = np.mean(subjs_acc)\n","    return met_mape, ordering\n","\n","def metabolic_rate_estimation(t, y_meas, tau=42):\n","    n_samp = len(t)\n","    A = np.zeros((n_samp,2))\n","    A[0,:] = [1,0]\n","    for i in range(1,n_samp):\n","        for j in range(2):\n","            dt = t[i] - t[i-1]\n","            if j == 0:\n","                A[i,j] = A[i-1,j]*(1-dt/tau)\n","            else:\n","                A[i,j] = A[i-1,j]*(1-dt/tau) + (dt/tau)\n","    x_star = np.dot(np.linalg.pinv(A),y_meas)\n","    y_bar = np.dot(A,x_star)\n","    mean_squared_err = np.dot(np.transpose(y_bar-y_meas),(y_bar-y_meas))/n_samp\n","    met_est = x_star[1]\n","    \n","    return met_est, y_bar, mean_squared_err\n","\n","# pull metabolics from the metabolics .csv file and the subject height/weight from the other .csv\n","def calc_metabolics2(data_dir, subj, visualize = False, add_heartrate = False, cond_len=14, len_cond_s = 300, end_time_len = 180):\n","    gen_files = os.listdir(data_dir+subj)\n","    t_mat = []\n","    met_mat = []\n","    hr_mat = []\n","    for filename in gen_files:\n","        if len(filename) >= 4:\n","            if filename[-4:] == 'xlsx': # metabolics file\n","                if add_heartrate:\n","                    met_array = np.array(pd.read_excel(data_dir+subj+'\\\\'+filename, skiprows=3, usecols=[9, 14, 15, 23, 35])) # left then right insole forces          \n","                else:\n","                    met_array = np.array(pd.read_excel(data_dir+subj+'\\\\'+filename, skiprows=3, usecols=[9, 14, 15, 35])) # left then right insole forces        \n","                # load starting time\n","                met_raw = np.array(pd.read_excel(data_dir+subj+'\\\\'+filename, usecols=[4], header=None))\n","                starting_time = met_raw[0:2]\n","                test = str(starting_time[0][0]) + ' ' + str(starting_time[1][0])\n","                test_dt = datetime.datetime.strptime(test, '%m/%d/%Y %I:%M:%S %p')    \n","                met_len, cols = met_array.shape\n","                cond_indeces = list(np.arange(1,cond_len+1))\n","                start_inds = ['start 01','start 02','start 03','start 04','start 05','start 06','start 07','start 08','start 09','start 10','start 11','start 12','start 13', 'start 14', 'start 15', 'start 16']\n","                start_inds = start_inds[:cond_len]\n","                hr_int_mat = np.zeros((cond_len, len_cond_s))\n","                met_int_mat = np.zeros((cond_len, len_cond_s))\n","                start_stamps = []\n","                met_inds = []\n","                met_start_inds = np.zeros(cond_len, dtype=int)\n","                hr = np.zeros(cond_len) # first value in each col is length to use of this placeholder vector\n","                met_2mins = np.zeros(cond_len)\n","                met_vals = np.zeros((cond_len,1))\n","                for cnd in range(cond_len): # adding to check for conditions out of order\n","                    for i in range(met_len):\n","                        if met_array[i,-1] == cond_indeces[cnd]:\n","                            met_inds.append(i)\n","                            break\n","                        if met_array[i,-1] == start_inds[cnd]:\n","                            start_ind = start_inds.index(met_array[i,-1])\n","                            met_start_inds[start_ind] = i\n","                    if i == met_len-1: # didn't find the condition\n","                        met_inds.append(-1)\n","                        met_start_inds[len(met_inds)-1] = -1\n","                        \n","                # take the average of vco2 and vo2 over the num of avg_breaths, then find W from met eq\n","                for i, ind in enumerate(met_inds):\n","                    if ind != -1: # there exists this conditions for this subject\n","                        end_time = met_array[ind,0]\n","                        start_ind = ind\n","                        start_time = end_time\n","\n","                        while (start_time.hour*3600 + start_time.minute*60 + start_time.second + end_time_len) > (end_time.hour*3600 + end_time.minute*60 + end_time.second):\n","                            start_ind -= 1 # decrement\n","                            start_time = met_array[start_ind,0]                    \n","                        vo2 = np.mean(met_array[start_ind:ind,1])\n","                        vco2 = np.mean(met_array[start_ind:ind,2])\n","                        met_vals[i] = (vo2*16.48 + vco2*4.48)/60.0 # BROCKWAY\n","\n","                        if add_heartrate: # store values in the hr\n","                            hr[i] = np.mean(met_array[start_ind:ind,-2])\n","                        \n","                for i, ind in enumerate(met_start_inds):\n","                    if ind != -1: # there exists this conditions for this subject\n","                        start_time = met_array[ind,0]\n","                        end_time = start_time\n","                        end_ind = ind\n","                        while((start_time.hour*3600 + start_time.minute*60 + start_time.second + 120) > (end_time.hour*3600 + end_time.minute*60 + end_time.second)): # til end _time is 2 mins more than start\n","                            end_ind += 1 # increment\n","                            end_time = met_array[end_ind,0]\n","                        # get the c02, v02 values for those times, compute met\n","                        vo2 = met_array[ind:end_ind,1]\n","                        vco2 = met_array[ind:end_ind,2]\n","                        met_vec = (vo2*16.48 + vco2*4.48)/60.0 # BROCKWAY\n","                        tvec = np.zeros(end_ind-ind)\n","                        for cnt,j in enumerate(range(ind,end_ind)):\n","                            time_stamp = met_array[j,0]\n","                            tvec[cnt] = time_stamp.hour*3600 + time_stamp.minute*60 + time_stamp.second\n","                        tvec = tvec - tvec[0] + 1 # offset the time so starts at 1\n","                        met_est, y_bar, mean_squared_err = metabolic_rate_estimation(tvec, met_vec)\n","                        met_2mins[i] = met_est\n","\n","                        # computing the vectors for each 6 minute interval of interpolated estimates\n","                        end_time2 = start_time\n","                        dt_s = start_time.hour*3600 + start_time.minute*60 + start_time.second\n","                        start_stamps.append(test_dt + datetime.timedelta(0, dt_s)) # adding time to datetime starting time\n","                        end_ind2 = ind\n","                        while((start_time.hour*3600 + start_time.minute*60 + start_time.second + len_cond_s) > (end_time2.hour*3600 + end_time2.minute*60 + end_time2.second)): # til end _time is X mins more than start\n","                            end_ind2 += 1 # increment\n","                            end_time2 = met_array[end_ind2,0]\n","                        # get the c02, v02 values for those times, compute met\n","                        vo2 = met_array[ind:end_ind2,1]\n","                        vco2 = met_array[ind:end_ind2,2]\n","                        hr_vec5 = met_array[ind:end_ind2,3]\n","                        met_vec5 = (vo2*16.48 + vco2*4.48)/60.0 # BROCKWAY\n","                        tvec5 = np.zeros(end_ind2-ind)\n","                        for cnt,j in enumerate(range(ind,end_ind2)):\n","                            time_stamp = met_array[j,0]\n","                            tvec5[cnt] = time_stamp.hour*3600 + time_stamp.minute*60 + time_stamp.second\n","                        tvec5 = tvec5 - tvec5[0] + 1 # offset the time so starts at 1\n","                        tvec5_int = np.arange(1,len_cond_s+1)\n","                        met_vec5_int = np.interp(np.array(tvec5_int,dtype='float64'), np.array(tvec5,dtype='float64'),np.array(met_vec5,dtype='float64'))\n","                        hr_vec5_int = np.interp(np.array(tvec5_int,dtype='float64'), np.array(tvec5,dtype='float64'),np.array(hr_vec5,dtype='float64'))\n","                        hr_int_mat[i,:] = hr_vec5_int\n","                        met_int_mat[i,:] = met_vec5_int\n","                cond_cnt = -1\n","                for i,ind in enumerate(met_start_inds):\n","                    if ind != -1: # there exists this conditions for this subject\n","                        cond_cnt += 1\n","                        stop_ind = met_inds[cond_cnt]\n","                        t_mat.append(met_array[ind:stop_ind,0])\n","                        met_mat_temp = (met_array[ind:stop_ind,1]*16.48 + met_array[ind:stop_ind,2]*4.48)/60.0\n","                        met_mat.append(met_mat_temp)\n","                        hr_mat.append(met_array[ind:stop_ind,-2])\n","                    else:\n","                        t_mat.append([-1])\n","                        met_mat.append([-1])\n","                        hr_mat.append([-1])\n","\n","                    \n","    return met_vals, hr, met_2mins, hr_int_mat, met_int_mat, start_stamps, t_mat, met_mat, hr_mat\n","\n","def load_constants2(cur_dir, subjects):\n","    code_files = os.listdir(cur_dir)\n","    print(code_files)\n","    for fnm in code_files:\n","        if len(fnm) >= 7:\n","            if fnm[-7:] == 'rt2.csv':\n","                subj_data = np.array(pd.read_csv(cur_dir+'\\\\'+fnm, sep=\",\", skiprows=0, usecols=[1,2]))\n","                num_subj, cols = subj_data.shape\n","                if len(subjects) <= num_subj:\n","                    masses = subj_data[:len(subjects),1]\n","                    heights = subj_data[:len(subjects),0]\n","                    return masses, heights\n","                else:\n","                    print(\"Trying to pull more subjects of data from code/subjects.csv than are there...\")\n","                    return\n","    print(\"No subjects.cvs file in the code folder...\")"]},{"cell_type":"code","source":[""],"metadata":{"id":"sad82wB7MASp"},"execution_count":null,"outputs":[]}]}